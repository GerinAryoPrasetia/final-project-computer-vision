{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfac50a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/gerinaryo/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2023-6-3 Python-3.10.11 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3070, 7966MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 212 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check your goldfish now!, position=196.0\n",
      "check your goldfish now!, position=197.0\n",
      "check your goldfish now!, position=187.0\n",
      "check your goldfish now!, position=187.0\n",
      "check your goldfish now!, position=177.0\n",
      "check your goldfish now!, position=177.0\n",
      "check your goldfish now!, position=165.0\n",
      "check your goldfish now!, position=165.0\n",
      "check your goldfish now!, position=155.0\n",
      "check your goldfish now!, position=155.0\n",
      "check your goldfish now!, position=142.0\n",
      "check your goldfish now!, position=142.0\n",
      "check your goldfish now!, position=126.0\n",
      "check your goldfish now!, position=126.0\n",
      "check your goldfish now!, position=118.0\n",
      "check your goldfish now!, position=118.0\n",
      "check your goldfish now!, position=116.0\n",
      "check your goldfish now!, position=116.0\n",
      "check your goldfish now!, position=92.0\n",
      "check your goldfish now!, position=92.0\n",
      "check your goldfish now!, position=81.0\n",
      "check your goldfish now!, position=81.0\n",
      "check your goldfish now!, position=78.0\n",
      "check your goldfish now!, position=91.0\n",
      "check your goldfish now!, position=91.0\n",
      "check your goldfish now!, position=97.0\n",
      "check your goldfish now!, position=97.0\n",
      "check your goldfish now!, position=104.0\n",
      "check your goldfish now!, position=104.0\n",
      "check your goldfish now!, position=114.0\n",
      "check your goldfish now!, position=115.0\n",
      "check your goldfish now!, position=124.0\n",
      "check your goldfish now!, position=124.0\n",
      "check your goldfish now!, position=135.0\n",
      "check your goldfish now!, position=135.0\n",
      "check your goldfish now!, position=145.0\n",
      "check your goldfish now!, position=145.0\n",
      "check your goldfish now!, position=153.0\n",
      "check your goldfish now!, position=153.0\n",
      "check your goldfish now!, position=163.0\n",
      "check your goldfish now!, position=163.0\n",
      "check your goldfish now!, position=170.0\n",
      "check your goldfish now!, position=170.0\n",
      "check your goldfish now!, position=178.0\n",
      "check your goldfish now!, position=178.0\n",
      "check your goldfish now!, position=189.0\n",
      "check your goldfish now!, position=189.0\n",
      "check your goldfish now!, position=196.0\n",
      "check your goldfish now!, position=196.0\n",
      "check your goldfish now!, position=198.0\n",
      "check your goldfish now!, position=198.0\n",
      "check your goldfish now!, position=198.0\n",
      "check your goldfish now!, position=198.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the YOLOv5 model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='best.pt')\n",
    "\n",
    "# Set the confidence threshold\n",
    "confidence_threshold = 0.5\n",
    "\n",
    "# Open the video file\n",
    "video_path = './yolov5/goldfish.mp4'\n",
    "video = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Define output video settings\n",
    "output_path = 'output.mp4'\n",
    "output_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "output_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "output_video = cv2.VideoWriter(output_path, fourcc, fps, (output_width, output_height))\n",
    "\n",
    "textLabel = \"\"\n",
    "\n",
    "while True:\n",
    "    # Read the current frame\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert frame to RGB format\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Perform object detection\n",
    "    results = model(frame_rgb)\n",
    "    \n",
    "    # Extract bounding boxes, labels, and scores from results\n",
    "    boxes = results.xyxy[0][:, :4].tolist()\n",
    "    labels = results.xyxy[0][:, 5].tolist()\n",
    "    scores = results.xyxy[0][:, 4].tolist()\n",
    "    \n",
    "    # Filter detections based on confidence threshold\n",
    "    filtered_boxes = []\n",
    "    filtered_labels = []\n",
    "    filtered_scores = []\n",
    "    \n",
    "    for box, label, score in zip(boxes, labels, scores):\n",
    "        if score > confidence_threshold:\n",
    "            filtered_boxes.append(box)\n",
    "            filtered_labels.append(label)\n",
    "            filtered_scores.append(score)\n",
    "    \n",
    "    # Render filtered detections on the frame\n",
    "    rendered_frame = frame.copy()\n",
    "    \n",
    "    for box, label, score in zip(filtered_boxes, filtered_labels, filtered_scores):\n",
    "        if label == 0.0:\n",
    "            textLabel = \"Goldfish\"\n",
    "        x1, y1, x2, y2 = box\n",
    "        cv2.rectangle(rendered_frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "        \n",
    "        # Calculate the centroid coordinates\n",
    "        centroid_x = (x1 + x2) // 2\n",
    "        centroid_y = (y1 + y2) // 2\n",
    "        \n",
    "        # Draw background rectangle for text\n",
    "        text = f'{textLabel}: {score:.2f}'\n",
    "        text_size, _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.9, 2)\n",
    "        cv2.rectangle(rendered_frame, (int(x1), int(y1)), (int(x1) + text_size[0] + 10, int(y1) - text_size[1] - 10), (0, 255, 0), cv2.FILLED)\n",
    "        \n",
    "        # Overlay text on top of the background rectangle\n",
    "        cv2.putText(rendered_frame, text, (int(x1) + 5, int(y1) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 0), 2)\n",
    "        \n",
    "        # Print the label and centroid coordinates\n",
    "#         print(f'{label}: centroid_x={centroid_x}, centroid_y={centroid_y}')\n",
    "        if centroid_y < 200:\n",
    "            print(f'check your goldfish now!, position={centroid_y}')\n",
    "    \n",
    "    # Write the frame to the output video\n",
    "    output_video.write(rendered_frame)\n",
    "    \n",
    "    # Display the frame\n",
    "    cv2.imshow('Frame', rendered_frame)\n",
    "    \n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and writer\n",
    "video.release()\n",
    "output_video.release()\n",
    "\n",
    "# Close all OpenCV windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb2816d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_viskom",
   "language": "python",
   "name": "final_viskom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
